{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d3e2bf5-4b5f-491c-ae62-e30b6608acc9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install -q accelerate==0.21.0 peft==0.4.0 bitsandbytes==0.40.2 transformers==4.31.0 trl==0.4.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0c9e865f-9ddb-4385-85b6-4946486c88e4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "from transformers import  AutoTokenizer\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdb18531-72ec-47d6-8c4e-447d2961a131",
   "metadata": {},
   "source": [
    "1. ### Create Llama-2-7b-chat-hf tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "35cfefe8-d726-41ee-9343-8ea733aa1174",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_name = \"NousResearch/Llama-2-7b-chat-hf\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = \"right\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9fb51ab4-6518-4d7a-b607-4e83a7468884",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "transformers.models.llama.tokenization_llama_fast.LlamaTokenizerFast"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95a396a2-5ec2-4c1e-b39f-0e8f47cf8a27",
   "metadata": {},
   "source": [
    "### 2. Look into token encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2f7ecd1c-0a53-4bd6-a405-07b820c15c26",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 445, 338, 263, 11203]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode(\"this is a dog\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7e15032-ee5a-4102-a4ae-f0d9bbad39b7",
   "metadata": {},
   "source": [
    "Let us try to decode this vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1ba6ac89-5dda-4d65-8b7f-60f2508f4e17",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('<s>', 'this', 'is', 'a', 'dog')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(1), tokenizer.decode(445), tokenizer.decode(338),tokenizer.decode(263), tokenizer.decode(11203)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b9742d6-4723-4965-a22f-ce6fa08c032b",
   "metadata": {},
   "source": [
    "We can see the mapping  'this' -> 445  'is' -> '338'  'a'->263 'dog' -> 11203,   token_id:1 i.e. `<s>` has been inserted into the start"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f139f13d-eac9-43b4-8c87-649243536e5a",
   "metadata": {},
   "source": [
    "we can even play it around further:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a1ed818a-e9ef-44ed-b768-44ee162b200d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1366"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.vocab[\"this\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "455ec391-002e-42a4-83b0-1a504569de73",
   "metadata": {
    "tags": []
   },
   "source": [
    "we can see the value is not encoded value  445, why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "326176e6-3a70-48ec-a015-b0ffc8bdd620",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "▁this\n",
      "this\n"
     ]
    }
   ],
   "source": [
    "for k, v in tokenizer.vocab.items():\n",
    "    if v in (1366, 445):\n",
    "        print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "69949bb8-fd82-43f8-9a90-db90735f46d1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('this', 'this')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(1366), tokenizer.decode(445)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed921ae0-2316-487d-b43d-aebf4100eb66",
   "metadata": {},
   "source": [
    "Interesting, there are two \"this\", one is '_this' 1366, the other is 445 'this'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53cab2a1-d15e-41a4-bc66-31a34c565191",
   "metadata": {},
   "source": [
    "The same for 'dog', the value is not 11203 we saw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "50bf828b-0fe6-4640-bb61-e9a6f9a48ce6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26169"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.vocab[\"dog\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a5c9e4e-a81d-4416-99fa-bccf987aad1c",
   "metadata": {},
   "source": [
    "Now the question is: how many different 'this' or 'dogs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4d1beaec-bc77-43ad-817e-8012ba82e392",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dog\n",
      "▁dog\n"
     ]
    }
   ],
   "source": [
    "for k, v in tokenizer.vocab.items():\n",
    "    if v in (26169, 11203):\n",
    "        print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c2071eb5-864a-45e8-a59c-7e9ed0e21b7c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "445\n",
      "1366\n"
     ]
    }
   ],
   "source": [
    "for k, v in tokenizer.vocab.items():\n",
    "    if tokenizer.decode(v) == 'this':\n",
    "        print(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5dac5047-f6c8-46a3-b928-c8647e628eb8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26169\n",
      "11203\n"
     ]
    }
   ],
   "source": [
    "for k, v in tokenizer.vocab.items():\n",
    "    if tokenizer.decode(v) == 'dog':\n",
    "        print(v)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d5cc300-c312-40a4-8062-7bc9eaae7e84",
   "metadata": {},
   "source": [
    "### 3. Further looking into encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f3e106d1-0bdc-4341-b387-4bd86fa0ad63",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 445, 4439, 2519, 338, 2812, 327, 300]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode(\"this malware is Emotet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "165d3dce-f33a-4aa5-8ee1-6eea065c9948",
   "metadata": {},
   "source": [
    "Let us check how malware, Emotet are encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b712764a-a1ea-420c-8ae0-60ec2ae8a0c0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'malware'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[41], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvocab\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmalware\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'malware'"
     ]
    }
   ],
   "source": [
    "tokenizer.vocab[\"malware\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c98277c-1811-457d-be7e-d46aa823fb5b",
   "metadata": {},
   "source": [
    "Clearly, malware is not in the vocabulary of tokenizer, so how is it encoded then?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f84def5a-3de0-4d2e-a7e0-45a1940978f2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('mal', 'ware')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(4439), tokenizer.decode(2519)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "addd94d2-31cf-4d2f-a82b-779c9712af6f",
   "metadata": {
    "tags": []
   },
   "source": [
    "Now we can, it has been splitted into 2 part, \"mal\", and \"ware\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d10662b-a723-4e6c-b0fa-ce4115b9bebc",
   "metadata": {},
   "source": [
    "The same for Emotet:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "21aa21a3-19ae-411e-8372-058a1506a6fb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Em', 'ot', 'et')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(2812), tokenizer.decode(327), tokenizer.decode(300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21f1257f-1a3a-4596-9b08-9668d78089e5",
   "metadata": {},
   "source": [
    "It has been split into 3 tokens. Now you know what token really means in LLM, usually it is one word, but not always"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35c38bc2-8ed3-4916-9425-6e4462492127",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
